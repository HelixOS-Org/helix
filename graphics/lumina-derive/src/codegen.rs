//! Code generation for shader derive macros.
//!
//! This module generates Rust code from shader definitions.

use crate::analyze::AnalysisContext;
use crate::error::Result;
use crate::ir_gen::IrModule;
use crate::parse::{ResourceKind, ShaderModule, ShaderStage};
use crate::spirv_gen::SpirVGenerator;
use proc_macro2::{Span, TokenStream};
use quote::{format_ident, quote, quote_spanned};
use syn::Ident;

/// Code generator for shader modules.
pub struct CodeGenerator {
    /// Whether to include debug info.
    debug: bool,
    /// Whether to embed SPIR-V in output.
    embed_spirv: bool,
    /// Module name.
    module_name: String,
}

impl CodeGenerator {
    /// Create a new code generator.
    pub fn new(module_name: &str) -> Self {
        Self {
            debug: false,
            embed_spirv: true,
            module_name: module_name.to_string(),
        }
    }

    /// Enable debug output.
    pub fn with_debug(mut self, debug: bool) -> Self {
        self.debug = debug;
        self
    }

    /// Enable SPIR-V embedding.
    pub fn with_embed_spirv(mut self, embed: bool) -> Self {
        self.embed_spirv = embed;
        self
    }

    /// Generate code from IR module.
    pub fn generate(&self, ir: &IrModule, ctx: &AnalysisContext) -> Result<TokenStream> {
        let module_ident = format_ident!("{}", self.module_name);

        // Generate SPIR-V
        let mut spirv_gen = SpirVGenerator::new();
        let spirv = spirv_gen.generate(ir)?;

        // Generate module contents
        let spirv_data = self.generate_spirv_data(&spirv);
        let shader_info = self.generate_shader_info(ctx);
        let entry_points = self.generate_entry_point_structs(ctx);
        let descriptor_layouts = self.generate_descriptor_layouts(ctx);
        let vertex_inputs = self.generate_vertex_inputs(ctx);
        let push_constants = self.generate_push_constants(ctx);
        let helper_functions = self.generate_helper_functions(ctx);

        let output = quote! {
            #[allow(dead_code, non_camel_case_types, non_snake_case)]
            pub mod #module_ident {
                //! Generated shader module.
                //!
                //! This module was generated by the LUMINA shader compiler.

                #spirv_data
                #shader_info
                #entry_points
                #descriptor_layouts
                #vertex_inputs
                #push_constants
                #helper_functions
            }
        };

        Ok(output)
    }

    fn generate_spirv_data(&self, spirv: &[u32]) -> TokenStream {
        if !self.embed_spirv {
            return quote! {};
        }

        let words = spirv.iter().map(|w| quote! { #w });
        let word_count = spirv.len();
        let byte_size = word_count * 4;

        quote! {
            /// SPIR-V shader binary.
            pub static SPIRV: &[u32] = &[#(#words),*];

            /// SPIR-V binary as bytes.
            pub fn spirv_bytes() -> &'static [u8] {
                unsafe {
                    core::slice::from_raw_parts(
                        SPIRV.as_ptr() as *const u8,
                        #byte_size,
                    )
                }
            }

            /// Size of SPIR-V binary in words.
            pub const SPIRV_WORD_COUNT: usize = #word_count;

            /// Size of SPIR-V binary in bytes.
            pub const SPIRV_BYTE_SIZE: usize = #byte_size;
        }
    }

    fn generate_shader_info(&self, ctx: &AnalysisContext) -> TokenStream {
        let entry_count = ctx.entry_points.len();
        let resource_count = ctx.resources.len();

        let stages: Vec<_> = ctx.entry_points.iter().map(|e| {
            let stage_name = format!("{:?}", e.stage);
            quote! { #stage_name }
        }).collect();

        let entry_names: Vec<_> = ctx.entry_points.iter().map(|e| {
            let name = &e.name;
            quote! { #name }
        }).collect();

        quote! {
            /// Shader module information.
            pub struct ShaderInfo;

            impl ShaderInfo {
                /// Number of entry points.
                pub const ENTRY_POINT_COUNT: usize = #entry_count;

                /// Number of resource bindings.
                pub const RESOURCE_COUNT: usize = #resource_count;

                /// Get entry point names.
                pub fn entry_point_names() -> &'static [&'static str] {
                    &[#(#entry_names),*]
                }

                /// Get shader stages.
                pub fn stages() -> &'static [&'static str] {
                    &[#(#stages),*]
                }
            }
        }
    }

    fn generate_entry_point_structs(&self, ctx: &AnalysisContext) -> TokenStream {
        let mut structs = Vec::new();

        for entry in &ctx.entry_points {
            let name = format_ident!("{}EntryPoint", to_pascal_case(&entry.name));
            let entry_name = &entry.name;
            let stage = format!("{:?}", entry.stage);

            let local_size = if let Some((x, y, z)) = entry.local_size {
                quote! {
                    /// Workgroup size.
                    pub const LOCAL_SIZE: (u32, u32, u32) = (#x, #y, #z);
                }
            } else {
                quote! {}
            };

            let input_fields: Vec<_> = entry.inputs.iter().map(|input| {
                let field_name = format_ident!("{}", input.name);
                let location = input.location.unwrap_or(0);
                let type_name = format!("{:?}", input.ty);
                quote! {
                    /// Input at location #location.
                    pub #field_name: (), // Type: #type_name
                }
            }).collect();

            let output_fields: Vec<_> = entry.outputs.iter().map(|output| {
                let field_name = format_ident!("{}", output.name);
                let location = output.location.unwrap_or(0);
                let type_name = format!("{:?}", output.ty);
                quote! {
                    /// Output at location #location.
                    pub #field_name: (), // Type: #type_name
                }
            }).collect();

            structs.push(quote! {
                /// Entry point: #entry_name
                pub struct #name;

                impl #name {
                    /// Entry point name.
                    pub const NAME: &'static str = #entry_name;

                    /// Shader stage.
                    pub const STAGE: &'static str = #stage;

                    #local_size
                }
            });
        }

        quote! {
            #(#structs)*
        }
    }

    fn generate_descriptor_layouts(&self, ctx: &AnalysisContext) -> TokenStream {
        // Group resources by set
        let mut sets: std::collections::HashMap<u32, Vec<_>> = std::collections::HashMap::new();
        for resource in &ctx.resources {
            if resource.kind != ResourceKind::PushConstant {
                sets.entry(resource.set).or_default().push(resource);
            }
        }

        let mut set_structs = Vec::new();

        for (set_idx, resources) in &sets {
            let set_name = format_ident!("DescriptorSet{}", set_idx);
            let binding_count = resources.len();

            let bindings: Vec<_> = resources.iter().map(|r| {
                let binding_idx = r.binding;
                let binding_name = format_ident!("{}", r.name.to_uppercase());
                let kind = match r.kind {
                    ResourceKind::UniformBuffer => "UNIFORM_BUFFER",
                    ResourceKind::StorageBuffer => "STORAGE_BUFFER",
                    ResourceKind::SampledImage => "SAMPLED_IMAGE",
                    ResourceKind::StorageImage => "STORAGE_IMAGE",
                    ResourceKind::Sampler => "SAMPLER",
                    ResourceKind::CombinedImageSampler => "COMBINED_IMAGE_SAMPLER",
                    ResourceKind::InputAttachment => "INPUT_ATTACHMENT",
                    ResourceKind::AccelerationStructure => "ACCELERATION_STRUCTURE",
                    _ => "UNKNOWN",
                };

                quote! {
                    /// Binding #binding_idx: #kind
                    pub const #binding_name: u32 = #binding_idx;
                }
            }).collect();

            set_structs.push(quote! {
                /// Descriptor set #set_idx layout.
                pub struct #set_name;

                impl #set_name {
                    /// Set index.
                    pub const SET: u32 = #set_idx;

                    /// Number of bindings.
                    pub const BINDING_COUNT: usize = #binding_count;

                    #(#bindings)*
                }
            });
        }

        if set_structs.is_empty() {
            return quote! {};
        }

        let set_count = sets.len();

        quote! {
            /// Descriptor set layouts.
            pub mod descriptors {
                /// Number of descriptor sets.
                pub const SET_COUNT: usize = #set_count;

                #(#set_structs)*
            }
        }
    }

    fn generate_vertex_inputs(&self, ctx: &AnalysisContext) -> TokenStream {
        // Find vertex shader
        let vertex = ctx.entry_points.iter()
            .find(|e| e.stage == ShaderStage::Vertex);

        let Some(vertex) = vertex else {
            return quote! {};
        };

        // Only location inputs, not builtins
        let inputs: Vec<_> = vertex.inputs.iter()
            .filter(|i| i.location.is_some())
            .collect();

        if inputs.is_empty() {
            return quote! {};
        }

        let attributes: Vec<_> = inputs.iter().map(|input| {
            let location = input.location.unwrap();
            let name = &input.name;
            let type_name = format!("{:?}", input.ty);

            quote! {
                VertexAttribute {
                    location: #location,
                    name: #name,
                    format: #type_name,
                }
            }
        }).collect();

        let attribute_count = attributes.len();

        quote! {
            /// Vertex input layout.
            pub mod vertex_input {
                /// Vertex attribute description.
                #[derive(Debug, Clone, Copy)]
                pub struct VertexAttribute {
                    pub location: u32,
                    pub name: &'static str,
                    pub format: &'static str,
                }

                /// Number of vertex attributes.
                pub const ATTRIBUTE_COUNT: usize = #attribute_count;

                /// Vertex attributes.
                pub static ATTRIBUTES: &[VertexAttribute] = &[
                    #(#attributes),*
                ];
            }
        }
    }

    fn generate_push_constants(&self, ctx: &AnalysisContext) -> TokenStream {
        let push_constants: Vec<_> = ctx.resources.iter()
            .filter(|r| r.kind == ResourceKind::PushConstant)
            .collect();

        if push_constants.is_empty() {
            return quote! {};
        }

        let structs: Vec<_> = push_constants.iter().map(|pc| {
            let name = format_ident!("{}Layout", to_pascal_case(&pc.name));
            let size = pc.ty.size();

            quote! {
                /// Push constant layout.
                pub struct #name;

                impl #name {
                    /// Size in bytes.
                    pub const SIZE: u32 = #size;
                }
            }
        }).collect();

        quote! {
            /// Push constant layouts.
            pub mod push_constants {
                #(#structs)*
            }
        }
    }

    fn generate_helper_functions(&self, ctx: &AnalysisContext) -> TokenStream {
        let has_vertex = ctx.entry_points.iter().any(|e| e.stage == ShaderStage::Vertex);
        let has_fragment = ctx.entry_points.iter().any(|e| e.stage == ShaderStage::Fragment);
        let has_compute = ctx.entry_points.iter().any(|e| e.stage == ShaderStage::Compute);

        let mut helpers = Vec::new();

        if has_vertex && has_fragment {
            helpers.push(quote! {
                /// Check if this is a graphics shader.
                pub const fn is_graphics() -> bool { true }
            });
        }

        if has_compute {
            let compute = ctx.entry_points.iter()
                .find(|e| e.stage == ShaderStage::Compute)
                .unwrap();

            if let Some((x, y, z)) = compute.local_size {
                helpers.push(quote! {
                    /// Calculate number of workgroups needed.
                    pub const fn workgroup_count(width: u32, height: u32, depth: u32) -> (u32, u32, u32) {
                        (
                            (width + #x - 1) / #x,
                            (height + #y - 1) / #y,
                            (depth + #z - 1) / #z,
                        )
                    }
                });
            }
        }

        let set_count = ctx.bindings.sets().len() as u32;

        helpers.push(quote! {
            /// Number of descriptor sets required.
            pub const DESCRIPTOR_SET_COUNT: u32 = #set_count;
        });

        quote! {
            #(#helpers)*
        }
    }
}

/// Generate entry point code.
pub fn generate_entry_point_code(
    stage: ShaderStage,
    name: &str,
    spirv: &[u32],
) -> TokenStream {
    let entry_name = name;
    let stage_str = format!("{:?}", stage);
    let word_count = spirv.len();
    let words = spirv.iter().map(|w| quote! { #w });

    quote! {
        /// Shader entry point information.
        pub mod entry_point {
            /// Entry point name.
            pub const NAME: &'static str = #entry_name;

            /// Shader stage.
            pub const STAGE: &'static str = #stage_str;

            /// SPIR-V binary.
            pub static SPIRV: &[u32] = &[#(#words),*];

            /// SPIR-V word count.
            pub const SPIRV_WORD_COUNT: usize = #word_count;
        }
    }
}

/// Generate reflection data structure.
pub fn generate_reflection(ctx: &AnalysisContext) -> TokenStream {
    let entry_count = ctx.entry_points.len();
    let resource_count = ctx.resources.len();

    let entries: Vec<_> = ctx.entry_points.iter().map(|e| {
        let name = &e.name;
        let stage = format!("{:?}", e.stage);
        let input_count = e.inputs.len();
        let output_count = e.outputs.len();

        quote! {
            ReflectionEntry {
                name: #name,
                stage: #stage,
                input_count: #input_count,
                output_count: #output_count,
            }
        }
    }).collect();

    let resources: Vec<_> = ctx.resources.iter().map(|r| {
        let name = &r.name;
        let kind = format!("{:?}", r.kind);
        let binding = r.binding;
        let set = r.set;

        quote! {
            ReflectionResource {
                name: #name,
                kind: #kind,
                binding: #binding,
                set: #set,
            }
        }
    }).collect();

    quote! {
        /// Shader reflection data.
        pub mod reflection {
            /// Entry point reflection.
            #[derive(Debug, Clone, Copy)]
            pub struct ReflectionEntry {
                pub name: &'static str,
                pub stage: &'static str,
                pub input_count: usize,
                pub output_count: usize,
            }

            /// Resource reflection.
            #[derive(Debug, Clone, Copy)]
            pub struct ReflectionResource {
                pub name: &'static str,
                pub kind: &'static str,
                pub binding: u32,
                pub set: u32,
            }

            /// Number of entry points.
            pub const ENTRY_COUNT: usize = #entry_count;

            /// Number of resources.
            pub const RESOURCE_COUNT: usize = #resource_count;

            /// Entry points.
            pub static ENTRIES: &[ReflectionEntry] = &[#(#entries),*];

            /// Resources.
            pub static RESOURCES: &[ReflectionResource] = &[#(#resources),*];
        }
    }
}

/// Convert snake_case to PascalCase.
fn to_pascal_case(s: &str) -> String {
    s.split('_')
        .map(|word| {
            let mut chars = word.chars();
            match chars.next() {
                Some(first) => first.to_uppercase().chain(chars).collect::<String>(),
                None => String::new(),
            }
        })
        .collect()
}

/// Convert PascalCase to snake_case.
fn to_snake_case(s: &str) -> String {
    let mut result = String::new();
    for (i, c) in s.chars().enumerate() {
        if c.is_uppercase() && i > 0 {
            result.push('_');
        }
        result.push(c.to_lowercase().next().unwrap());
    }
    result
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_to_pascal_case() {
        assert_eq!(to_pascal_case("hello_world"), "HelloWorld");
        assert_eq!(to_pascal_case("vertex_main"), "VertexMain");
        assert_eq!(to_pascal_case("my_shader"), "MyShader");
    }

    #[test]
    fn test_to_snake_case() {
        assert_eq!(to_snake_case("HelloWorld"), "hello_world");
        assert_eq!(to_snake_case("VertexMain"), "vertex_main");
        assert_eq!(to_snake_case("MyShader"), "my_shader");
    }

    #[test]
    fn test_code_generator_new() {
        let gen = CodeGenerator::new("test");
        assert_eq!(gen.module_name, "test");
        assert!(!gen.debug);
        assert!(gen.embed_spirv);
    }
}
